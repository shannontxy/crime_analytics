{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Libraries\n",
    "%matplotlib inline \n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from urllib.request import urlopen \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_classification\n",
    "from collections import OrderedDict  \n",
    "data_path = r\"C:\\Users\\jethr\\ICPSR_36404-V2\\ICPSR_36404\\DS0001\\36404-0001-Data.tsv\"\n",
    "sb.set() # set the default Seaborn style for graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_df(filename):\n",
    "    df = pd.read_csv(data_path, header=0, sep=\"\\t\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation/Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jethr\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3338: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABT_INMATE_ID        object\n",
      "SEX                   int64\n",
      "ADMTYPE               int64\n",
      "OFFGENERAL            int64\n",
      "EDUCATION             int64\n",
      "ADMITYR               int64\n",
      "RELEASEYR             int64\n",
      "MAND_PRISREL_YEAR    object\n",
      "PROJ_PRISREL_YEAR    object\n",
      "PARELIG_YEAR         object\n",
      "SENTLGTH             object\n",
      "OFFDETAIL             int64\n",
      "RACE                  int64\n",
      "AGEADMIT              int64\n",
      "AGERELEASE           object\n",
      "TIMESRVD              int64\n",
      "RELTYPE              object\n",
      "STATE                 int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = build_df(data_path)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(\" \", np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABT_INMATE_ID</th>\n",
       "      <th>SEX</th>\n",
       "      <th>ADMTYPE</th>\n",
       "      <th>OFFGENERAL</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>ADMITYR</th>\n",
       "      <th>RELEASEYR</th>\n",
       "      <th>MAND_PRISREL_YEAR</th>\n",
       "      <th>PROJ_PRISREL_YEAR</th>\n",
       "      <th>PARELIG_YEAR</th>\n",
       "      <th>SENTLGTH</th>\n",
       "      <th>OFFDETAIL</th>\n",
       "      <th>RACE</th>\n",
       "      <th>AGEADMIT</th>\n",
       "      <th>AGERELEASE</th>\n",
       "      <th>TIMESRVD</th>\n",
       "      <th>RELTYPE</th>\n",
       "      <th>STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A012015000000091071</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2006</td>\n",
       "      <td>2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A022015000000096906</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A042015000000118649</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2013</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A062015000000167469</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1996</td>\n",
       "      <td>1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A132015000000550479</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1968</td>\n",
       "      <td>1972</td>\n",
       "      <td>1978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ABT_INMATE_ID  SEX  ADMTYPE  OFFGENERAL  EDUCATION  ADMITYR  \\\n",
       "0  A012015000000091071    1        1           2          9     2006   \n",
       "1  A022015000000096906    1        3           3          9     2008   \n",
       "2  A042015000000118649    1        1           1          9     2013   \n",
       "3  A062015000000167469    1        2           2          9     1996   \n",
       "4  A132015000000550479    1        1           1          9     1968   \n",
       "\n",
       "   RELEASEYR MAND_PRISREL_YEAR PROJ_PRISREL_YEAR PARELIG_YEAR SENTLGTH  \\\n",
       "0       2010               NaN               NaN          NaN        4   \n",
       "1       2008               NaN               NaN          NaN        0   \n",
       "2       2014              2014              2014          NaN        0   \n",
       "3       1996               NaN               NaN          NaN        2   \n",
       "4       1972              1978               NaN          NaN        3   \n",
       "\n",
       "   OFFDETAIL  RACE  AGEADMIT AGERELEASE  TIMESRVD RELTYPE  STATE  \n",
       "0         10     9         3          3         2       3      1  \n",
       "1         12     1         3          3         0     NaN      2  \n",
       "2          6     1         1          1         0       1      4  \n",
       "3          7     1         2          2         0       1      6  \n",
       "4          4     1         1          1         2       1     13  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type :  <class 'pandas.core.frame.DataFrame'>\n",
      "Data dims :  (10907333, 18)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data type : \", type(df))\n",
    "print(\"Data dims : \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABT_INMATE_ID              0\n",
      "SEX                        0\n",
      "ADMTYPE                    0\n",
      "OFFGENERAL                 0\n",
      "EDUCATION                  0\n",
      "ADMITYR                    0\n",
      "RELEASEYR                  0\n",
      "MAND_PRISREL_YEAR    7209317\n",
      "PROJ_PRISREL_YEAR    4662333\n",
      "PARELIG_YEAR         8148769\n",
      "SENTLGTH               20063\n",
      "OFFDETAIL                  0\n",
      "RACE                       0\n",
      "AGEADMIT                   0\n",
      "AGERELEASE           1200886\n",
      "TIMESRVD                   0\n",
      "RELTYPE              1809372\n",
      "STATE                      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1bb3434a340>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "missing_data = df.isnull().sum()\n",
    "print(missing_data)\n",
    "missing_data.plot(kind='bar', color='Red', title=\"Number of Rows Missing Data\", grid=True).legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the above graph, most of the missing data are related to the year when the prisoner is going to be released. For example, some columns such as PARELIG_YEAR are missing almost 80% of their values. Therefore, we cannot impute the values in these columns as more data is missing than available. It is best that we drop all missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_rows = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABT_INMATE_ID</th>\n",
       "      <th>SEX</th>\n",
       "      <th>ADMTYPE</th>\n",
       "      <th>OFFGENERAL</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>ADMITYR</th>\n",
       "      <th>RELEASEYR</th>\n",
       "      <th>MAND_PRISREL_YEAR</th>\n",
       "      <th>PROJ_PRISREL_YEAR</th>\n",
       "      <th>PARELIG_YEAR</th>\n",
       "      <th>SENTLGTH</th>\n",
       "      <th>OFFDETAIL</th>\n",
       "      <th>RACE</th>\n",
       "      <th>AGEADMIT</th>\n",
       "      <th>AGERELEASE</th>\n",
       "      <th>TIMESRVD</th>\n",
       "      <th>RELTYPE</th>\n",
       "      <th>STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A182015000000019353</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>2009</td>\n",
       "      <td>2010</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>A442015000000038143</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2007</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287979</th>\n",
       "      <td>A042015000000273326</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404424</th>\n",
       "      <td>A042015000000190084</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488157</th>\n",
       "      <td>A042015000000224709</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ABT_INMATE_ID  SEX  ADMTYPE  OFFGENERAL  EDUCATION  ADMITYR  \\\n",
       "6       A182015000000019353    2        3           3          9     2008   \n",
       "23      A442015000000038143    1        1           3          9     2007   \n",
       "287979  A042015000000273326    1        1           2          9     2012   \n",
       "404424  A042015000000190084    1        1           1          9     2012   \n",
       "488157  A042015000000224709    1        2           1          9     2012   \n",
       "\n",
       "        RELEASEYR MAND_PRISREL_YEAR PROJ_PRISREL_YEAR PARELIG_YEAR SENTLGTH  \\\n",
       "6            2009              2010              2009         2009        2   \n",
       "23           2008              2008              2008         2007        1   \n",
       "287979       2013              2013              2013         2013        3   \n",
       "404424       2014              2014              2014         2014        3   \n",
       "488157       2013              2013              2013         2011        4   \n",
       "\n",
       "        OFFDETAIL  RACE  AGEADMIT AGERELEASE  TIMESRVD RELTYPE  STATE  \n",
       "6              12     1         2          2         0       1     18  \n",
       "23             12     2         4          4         1       2     44  \n",
       "287979         10     1         5          5         1       1      4  \n",
       "404424          1     1         4          4         1       1      4  \n",
       "488157          3     1         5          5         0       1      4  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_rows.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert relevant data types from object to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-cf14f2ca324f>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_rows['MAND_PRISREL_YEAR'] = complete_rows['MAND_PRISREL_YEAR'].astype(str).astype(int)\n",
      "<ipython-input-10-cf14f2ca324f>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_rows['PROJ_PRISREL_YEAR'] = complete_rows['PROJ_PRISREL_YEAR'].astype(str).astype(int)\n",
      "<ipython-input-10-cf14f2ca324f>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_rows['PARELIG_YEAR'] = complete_rows['PARELIG_YEAR'].astype(str).astype(int)\n",
      "<ipython-input-10-cf14f2ca324f>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_rows['AGERELEASE'] = complete_rows['AGERELEASE'].astype(str).astype(int)\n",
      "<ipython-input-10-cf14f2ca324f>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_rows['RELTYPE'] = complete_rows['RELTYPE'].astype(str).astype(int)\n",
      "<ipython-input-10-cf14f2ca324f>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_rows['SENTLGTH'] = complete_rows['SENTLGTH'].astype(str).astype(int)\n"
     ]
    }
   ],
   "source": [
    "complete_rows['MAND_PRISREL_YEAR'] = complete_rows['MAND_PRISREL_YEAR'].astype(str).astype(int)\n",
    "complete_rows['PROJ_PRISREL_YEAR'] = complete_rows['PROJ_PRISREL_YEAR'].astype(str).astype(int)\n",
    "complete_rows['PARELIG_YEAR'] = complete_rows['PARELIG_YEAR'].astype(str).astype(int)\n",
    "complete_rows['AGERELEASE'] = complete_rows['AGERELEASE'].astype(str).astype(int)\n",
    "complete_rows['RELTYPE'] = complete_rows['RELTYPE'].astype(str).astype(int)\n",
    "complete_rows['SENTLGTH'] = complete_rows['SENTLGTH'].astype(str).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert relevant data types from object to categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-30e05d9d4249>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_rows['SEX'] = complete_rows['SEX'].astype(\"category\")\n",
      "<ipython-input-11-30e05d9d4249>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_rows['ADMTYPE'] = complete_rows['ADMTYPE'].astype(\"category\")\n",
      "<ipython-input-11-30e05d9d4249>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_rows['OFFGENERAL'] = complete_rows['OFFGENERAL'].astype(\"category\")\n",
      "<ipython-input-11-30e05d9d4249>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_rows['EDUCATION'] = complete_rows['EDUCATION'].astype(\"category\")\n",
      "<ipython-input-11-30e05d9d4249>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_rows['SENTLGTH'] = complete_rows['SENTLGTH'].astype(\"category\")\n",
      "<ipython-input-11-30e05d9d4249>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_rows['OFFDETAIL'] = complete_rows['OFFDETAIL'].astype(\"category\")\n",
      "<ipython-input-11-30e05d9d4249>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_rows['RACE'] = complete_rows['RACE'].astype(\"category\")\n",
      "<ipython-input-11-30e05d9d4249>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_rows['AGEADMIT'] = complete_rows['AGEADMIT'].astype(\"category\")\n",
      "<ipython-input-11-30e05d9d4249>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_rows['AGERELEASE'] = complete_rows['AGERELEASE'].astype(\"category\")\n",
      "<ipython-input-11-30e05d9d4249>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_rows['TIMESRVD'] = complete_rows['TIMESRVD'].astype(\"category\")\n",
      "<ipython-input-11-30e05d9d4249>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_rows['RELTYPE'] = complete_rows['RELTYPE'].astype(\"category\")\n",
      "<ipython-input-11-30e05d9d4249>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_rows['STATE'] = complete_rows['STATE'].astype(\"category\")\n"
     ]
    }
   ],
   "source": [
    "complete_rows['SEX'] = complete_rows['SEX'].astype(\"category\")\n",
    "complete_rows['ADMTYPE'] = complete_rows['ADMTYPE'].astype(\"category\")\n",
    "complete_rows['OFFGENERAL'] = complete_rows['OFFGENERAL'].astype(\"category\")\n",
    "complete_rows['EDUCATION'] = complete_rows['EDUCATION'].astype(\"category\")\n",
    "complete_rows['SENTLGTH'] = complete_rows['SENTLGTH'].astype(\"category\")\n",
    "complete_rows['OFFDETAIL'] = complete_rows['OFFDETAIL'].astype(\"category\")\n",
    "complete_rows['RACE'] = complete_rows['RACE'].astype(\"category\")\n",
    "complete_rows['AGEADMIT'] = complete_rows['AGEADMIT'].astype(\"category\")\n",
    "complete_rows['AGERELEASE'] = complete_rows['AGERELEASE'].astype(\"category\")\n",
    "complete_rows['TIMESRVD'] = complete_rows['TIMESRVD'].astype(\"category\")\n",
    "complete_rows['RELTYPE'] = complete_rows['RELTYPE'].astype(\"category\")\n",
    "complete_rows['STATE'] = complete_rows['STATE'].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABT_INMATE_ID          object\n",
      "SEX                  category\n",
      "ADMTYPE              category\n",
      "OFFGENERAL           category\n",
      "EDUCATION            category\n",
      "ADMITYR                 int64\n",
      "RELEASEYR               int64\n",
      "MAND_PRISREL_YEAR       int32\n",
      "PROJ_PRISREL_YEAR       int32\n",
      "PARELIG_YEAR            int32\n",
      "SENTLGTH             category\n",
      "OFFDETAIL            category\n",
      "RACE                 category\n",
      "AGEADMIT             category\n",
      "AGERELEASE           category\n",
      "TIMESRVD             category\n",
      "RELTYPE              category\n",
      "STATE                category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(complete_rows.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720189\n"
     ]
    }
   ],
   "source": [
    "print(len(complete_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, eventhough we have dropped more than 90% of the data, we are still left with 720K rows which is more than enough to work with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABT_INMATE_ID</th>\n",
       "      <th>SEX</th>\n",
       "      <th>ADMTYPE</th>\n",
       "      <th>OFFGENERAL</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>ADMITYR</th>\n",
       "      <th>RELEASEYR</th>\n",
       "      <th>MAND_PRISREL_YEAR</th>\n",
       "      <th>PROJ_PRISREL_YEAR</th>\n",
       "      <th>PARELIG_YEAR</th>\n",
       "      <th>SENTLGTH</th>\n",
       "      <th>OFFDETAIL</th>\n",
       "      <th>RACE</th>\n",
       "      <th>AGEADMIT</th>\n",
       "      <th>AGERELEASE</th>\n",
       "      <th>TIMESRVD</th>\n",
       "      <th>RELTYPE</th>\n",
       "      <th>STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A182015000000019353</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>2009</td>\n",
       "      <td>2010</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>A442015000000038143</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2007</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287979</th>\n",
       "      <td>A042015000000273326</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404424</th>\n",
       "      <td>A042015000000190084</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488157</th>\n",
       "      <td>A042015000000224709</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ABT_INMATE_ID SEX ADMTYPE OFFGENERAL EDUCATION  ADMITYR  \\\n",
       "6       A182015000000019353   2       3          3         9     2008   \n",
       "23      A442015000000038143   1       1          3         9     2007   \n",
       "287979  A042015000000273326   1       1          2         9     2012   \n",
       "404424  A042015000000190084   1       1          1         9     2012   \n",
       "488157  A042015000000224709   1       2          1         9     2012   \n",
       "\n",
       "        RELEASEYR  MAND_PRISREL_YEAR  PROJ_PRISREL_YEAR  PARELIG_YEAR  \\\n",
       "6            2009               2010               2009          2009   \n",
       "23           2008               2008               2008          2007   \n",
       "287979       2013               2013               2013          2013   \n",
       "404424       2014               2014               2014          2014   \n",
       "488157       2013               2013               2013          2011   \n",
       "\n",
       "       SENTLGTH OFFDETAIL RACE AGEADMIT AGERELEASE TIMESRVD RELTYPE STATE  \n",
       "6             2        12    1        2          2        0       1    18  \n",
       "23            1        12    2        4          4        1       2    44  \n",
       "287979        3        10    1        5          5        1       1     4  \n",
       "404424        3         1    1        4          4        1       1     4  \n",
       "488157        4         3    1        5          5        0       1     4  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_rows.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data file contains one record for each separate term in prison. An individual person may have more than one record, but all will be assigned the same Abt_Inmate_ID value. Thus, we iterate through the dataset to find deuplicate copies of Abt_Inmate_ID value which indicates that the felony has recommited a crime. We will mark 0 as non-repeated offender and 1 as repeated offender. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat = complete_rows.set_index('ABT_INMATE_ID').index.duplicated(keep=False) #If the index is duplicated, TRUE, else FALSE\n",
    "repeat = repeat * 1 #Change true and false to 1 and 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "recividism = [x + 0 for x in repeat] #add 1 to all the numbers in repeat.\n",
    "se = pd.Series(recividism)\n",
    "complete_rows.insert(0, 'recidivism', se.values) #insert this row inside\n",
    "#it will be binary from now on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recidivism</th>\n",
       "      <th>ABT_INMATE_ID</th>\n",
       "      <th>SEX</th>\n",
       "      <th>ADMTYPE</th>\n",
       "      <th>OFFGENERAL</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>ADMITYR</th>\n",
       "      <th>RELEASEYR</th>\n",
       "      <th>MAND_PRISREL_YEAR</th>\n",
       "      <th>PROJ_PRISREL_YEAR</th>\n",
       "      <th>PARELIG_YEAR</th>\n",
       "      <th>SENTLGTH</th>\n",
       "      <th>OFFDETAIL</th>\n",
       "      <th>RACE</th>\n",
       "      <th>AGEADMIT</th>\n",
       "      <th>AGERELEASE</th>\n",
       "      <th>TIMESRVD</th>\n",
       "      <th>RELTYPE</th>\n",
       "      <th>STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>A182015000000019353</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>2009</td>\n",
       "      <td>2010</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>A442015000000038143</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2007</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287979</th>\n",
       "      <td>0</td>\n",
       "      <td>A042015000000273326</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404424</th>\n",
       "      <td>0</td>\n",
       "      <td>A042015000000190084</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488157</th>\n",
       "      <td>0</td>\n",
       "      <td>A042015000000224709</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        recidivism        ABT_INMATE_ID SEX ADMTYPE OFFGENERAL EDUCATION  \\\n",
       "6                1  A182015000000019353   2       3          3         9   \n",
       "23               1  A442015000000038143   1       1          3         9   \n",
       "287979           0  A042015000000273326   1       1          2         9   \n",
       "404424           0  A042015000000190084   1       1          1         9   \n",
       "488157           0  A042015000000224709   1       2          1         9   \n",
       "\n",
       "        ADMITYR  RELEASEYR  MAND_PRISREL_YEAR  PROJ_PRISREL_YEAR  \\\n",
       "6          2008       2009               2010               2009   \n",
       "23         2007       2008               2008               2008   \n",
       "287979     2012       2013               2013               2013   \n",
       "404424     2012       2014               2014               2014   \n",
       "488157     2012       2013               2013               2013   \n",
       "\n",
       "        PARELIG_YEAR SENTLGTH OFFDETAIL RACE AGEADMIT AGERELEASE TIMESRVD  \\\n",
       "6               2009        2        12    1        2          2        0   \n",
       "23              2007        1        12    2        4          4        1   \n",
       "287979          2013        3        10    1        5          5        1   \n",
       "404424          2014        3         1    1        4          4        1   \n",
       "488157          2011        4         3    1        5          5        0   \n",
       "\n",
       "       RELTYPE STATE  \n",
       "6            1    18  \n",
       "23           2    44  \n",
       "287979       1     4  \n",
       "404424       1     4  \n",
       "488157       1     4  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_rows.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will proceed to drop 'ABT_INMATE_ID' as it will not be used for our machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jethr\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "<ipython-input-18-a71639884402>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_rows['recidivism'] = complete_rows['recidivism'].astype(\"category\")\n"
     ]
    }
   ],
   "source": [
    "complete_rows.drop('ABT_INMATE_ID', axis=1, inplace = True)\n",
    "complete_rows['recidivism'] = complete_rows['recidivism'].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I remove all the rows that have \"missing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_rows = complete_rows[complete_rows.RELEASEYR != 9999]\n",
    "complete_rows = complete_rows[complete_rows.ADMTYPE != 9]\n",
    "complete_rows = complete_rows[complete_rows.OFFGENERAL != 9]\n",
    "complete_rows = complete_rows[complete_rows.ADMITYR != 9999]\n",
    "complete_rows = complete_rows[complete_rows.OFFDETAIL != 99]\n",
    "complete_rows = complete_rows[complete_rows.RACE != 9]\n",
    "complete_rows = complete_rows[complete_rows.AGEADMIT != 9]\n",
    "complete_rows.drop('EDUCATION', axis=1, inplace=True) # missing all values\n",
    "complete_rows = complete_rows[complete_rows.MAND_PRISREL_YEAR != 9999]\n",
    "complete_rows = complete_rows[complete_rows.MAND_PRISREL_YEAR != 9993]\n",
    "complete_rows = complete_rows[complete_rows.PROJ_PRISREL_YEAR != 9999]\n",
    "complete_rows = complete_rows[complete_rows.PARELIG_YEAR != 9999]\n",
    "complete_rows = complete_rows[complete_rows.OFFDETAIL != 9]\n",
    "complete_rows = complete_rows[complete_rows.SENTLGTH != 9]\n",
    "complete_rows = complete_rows[complete_rows.AGERELEASE != 9]\n",
    "complete_rows = complete_rows[complete_rows.RELTYPE != 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created complete_rows2 as random forest and Decision Tree do not require standardScaling of continuous variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recidivism</th>\n",
       "      <th>SEX</th>\n",
       "      <th>ADMTYPE</th>\n",
       "      <th>OFFGENERAL</th>\n",
       "      <th>ADMITYR</th>\n",
       "      <th>RELEASEYR</th>\n",
       "      <th>MAND_PRISREL_YEAR</th>\n",
       "      <th>PROJ_PRISREL_YEAR</th>\n",
       "      <th>PARELIG_YEAR</th>\n",
       "      <th>SENTLGTH</th>\n",
       "      <th>OFFDETAIL</th>\n",
       "      <th>RACE</th>\n",
       "      <th>AGEADMIT</th>\n",
       "      <th>AGERELEASE</th>\n",
       "      <th>TIMESRVD</th>\n",
       "      <th>RELTYPE</th>\n",
       "      <th>STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.281023</td>\n",
       "      <td>0.018399</td>\n",
       "      <td>-0.046774</td>\n",
       "      <td>-0.097914</td>\n",
       "      <td>0.015980</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.071847</td>\n",
       "      <td>-0.270770</td>\n",
       "      <td>-0.099855</td>\n",
       "      <td>-0.159550</td>\n",
       "      <td>-0.050625</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287979</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.117729</td>\n",
       "      <td>1.175077</td>\n",
       "      <td>0.032847</td>\n",
       "      <td>0.148631</td>\n",
       "      <td>0.149188</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404424</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.117729</td>\n",
       "      <td>1.464246</td>\n",
       "      <td>0.059387</td>\n",
       "      <td>0.210267</td>\n",
       "      <td>0.182490</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488157</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.117729</td>\n",
       "      <td>1.175077</td>\n",
       "      <td>0.032847</td>\n",
       "      <td>0.148631</td>\n",
       "      <td>0.082584</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       recidivism SEX ADMTYPE OFFGENERAL   ADMITYR  RELEASEYR  \\\n",
       "6               1   2       3          3  0.281023   0.018399   \n",
       "23              1   1       1          3  0.071847  -0.270770   \n",
       "287979          0   1       1          2  1.117729   1.175077   \n",
       "404424          0   1       1          1  1.117729   1.464246   \n",
       "488157          0   1       2          1  1.117729   1.175077   \n",
       "\n",
       "        MAND_PRISREL_YEAR  PROJ_PRISREL_YEAR  PARELIG_YEAR SENTLGTH OFFDETAIL  \\\n",
       "6               -0.046774          -0.097914      0.015980        2        12   \n",
       "23              -0.099855          -0.159550     -0.050625        1        12   \n",
       "287979           0.032847           0.148631      0.149188        3        10   \n",
       "404424           0.059387           0.210267      0.182490        3         1   \n",
       "488157           0.032847           0.148631      0.082584        4         3   \n",
       "\n",
       "       RACE AGEADMIT AGERELEASE TIMESRVD RELTYPE STATE  \n",
       "6         1        2          2        0       1    18  \n",
       "23        2        4          4        1       2    44  \n",
       "287979    1        5          5        1       1     4  \n",
       "404424    1        4          4        1       1     4  \n",
       "488157    1        5          5        0       1     4  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_rows.head()\n",
    "complete_rows2 = complete_rows.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying StandardScaler for continuous variables (only applicable to neural network dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate data standardization with sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "columns = ['ADMITYR', 'RELEASEYR', 'MAND_PRISREL_YEAR', 'PROJ_PRISREL_YEAR', 'PARELIG_YEAR']\n",
    "for i in columns:\n",
    "    # load data\n",
    "    data = complete_rows[i].values.reshape(-1,1)\n",
    "    # create scaler\n",
    "    scaler = StandardScaler()\n",
    "    # fit and transform in one step\n",
    "    complete_rows[i] = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recidivism</th>\n",
       "      <th>SEX</th>\n",
       "      <th>ADMTYPE</th>\n",
       "      <th>OFFGENERAL</th>\n",
       "      <th>ADMITYR</th>\n",
       "      <th>RELEASEYR</th>\n",
       "      <th>MAND_PRISREL_YEAR</th>\n",
       "      <th>PROJ_PRISREL_YEAR</th>\n",
       "      <th>PARELIG_YEAR</th>\n",
       "      <th>SENTLGTH</th>\n",
       "      <th>OFFDETAIL</th>\n",
       "      <th>RACE</th>\n",
       "      <th>AGEADMIT</th>\n",
       "      <th>AGERELEASE</th>\n",
       "      <th>TIMESRVD</th>\n",
       "      <th>RELTYPE</th>\n",
       "      <th>STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.281023</td>\n",
       "      <td>0.018399</td>\n",
       "      <td>-0.046774</td>\n",
       "      <td>-0.097914</td>\n",
       "      <td>0.015980</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.071847</td>\n",
       "      <td>-0.270770</td>\n",
       "      <td>-0.099855</td>\n",
       "      <td>-0.159550</td>\n",
       "      <td>-0.050625</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287979</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.117729</td>\n",
       "      <td>1.175077</td>\n",
       "      <td>0.032847</td>\n",
       "      <td>0.148631</td>\n",
       "      <td>0.149188</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404424</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.117729</td>\n",
       "      <td>1.464246</td>\n",
       "      <td>0.059387</td>\n",
       "      <td>0.210267</td>\n",
       "      <td>0.182490</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488157</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.117729</td>\n",
       "      <td>1.175077</td>\n",
       "      <td>0.032847</td>\n",
       "      <td>0.148631</td>\n",
       "      <td>0.082584</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491650</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.117729</td>\n",
       "      <td>1.464246</td>\n",
       "      <td>0.032847</td>\n",
       "      <td>0.148631</td>\n",
       "      <td>0.149188</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743263</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.392387</td>\n",
       "      <td>-2.294955</td>\n",
       "      <td>0.245169</td>\n",
       "      <td>-0.529367</td>\n",
       "      <td>0.382303</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086862</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.490200</td>\n",
       "      <td>0.018399</td>\n",
       "      <td>-0.073314</td>\n",
       "      <td>-0.406095</td>\n",
       "      <td>-0.117229</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2942323</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.699376</td>\n",
       "      <td>0.596738</td>\n",
       "      <td>-0.020234</td>\n",
       "      <td>-0.221186</td>\n",
       "      <td>0.215792</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075560</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.326905</td>\n",
       "      <td>1.464246</td>\n",
       "      <td>0.085927</td>\n",
       "      <td>0.271903</td>\n",
       "      <td>0.182490</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        recidivism SEX ADMTYPE OFFGENERAL   ADMITYR  RELEASEYR  \\\n",
       "6                1   2       3          3  0.281023   0.018399   \n",
       "23               1   1       1          3  0.071847  -0.270770   \n",
       "287979           0   1       1          2  1.117729   1.175077   \n",
       "404424           0   1       1          1  1.117729   1.464246   \n",
       "488157           0   1       2          1  1.117729   1.175077   \n",
       "491650           0   1       1          1  1.117729   1.464246   \n",
       "743263           0   1       2          2 -1.392387  -2.294955   \n",
       "2086862          0   2       2          1  0.490200   0.018399   \n",
       "2942323          0   2       2          2  0.699376   0.596738   \n",
       "3075560          0   1       1          1  1.326905   1.464246   \n",
       "\n",
       "         MAND_PRISREL_YEAR  PROJ_PRISREL_YEAR  PARELIG_YEAR SENTLGTH  \\\n",
       "6                -0.046774          -0.097914      0.015980        2   \n",
       "23               -0.099855          -0.159550     -0.050625        1   \n",
       "287979            0.032847           0.148631      0.149188        3   \n",
       "404424            0.059387           0.210267      0.182490        3   \n",
       "488157            0.032847           0.148631      0.082584        4   \n",
       "491650            0.032847           0.148631      0.149188        3   \n",
       "743263            0.245169          -0.529367      0.382303        2   \n",
       "2086862          -0.073314          -0.406095     -0.117229        2   \n",
       "2942323          -0.020234          -0.221186      0.215792        2   \n",
       "3075560           0.085927           0.271903      0.182490        2   \n",
       "\n",
       "        OFFDETAIL RACE AGEADMIT AGERELEASE TIMESRVD RELTYPE STATE  \n",
       "6              12    1        2          2        0       1    18  \n",
       "23             12    2        4          4        1       2    44  \n",
       "287979         10    1        5          5        1       1     4  \n",
       "404424          1    1        4          4        1       1     4  \n",
       "488157          3    1        5          5        0       1     4  \n",
       "491650          3    1        3          3        1       1     4  \n",
       "743263          7    3        2          2        1       1     6  \n",
       "2086862         5    2        4          4        0       2     6  \n",
       "2942323        11    1        3          3        0       1     6  \n",
       "3075560         6    3        2          2        0       1     8  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_rows.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recidivism</th>\n",
       "      <th>SEX</th>\n",
       "      <th>ADMTYPE</th>\n",
       "      <th>OFFGENERAL</th>\n",
       "      <th>ADMITYR</th>\n",
       "      <th>RELEASEYR</th>\n",
       "      <th>MAND_PRISREL_YEAR</th>\n",
       "      <th>PROJ_PRISREL_YEAR</th>\n",
       "      <th>PARELIG_YEAR</th>\n",
       "      <th>SENTLGTH</th>\n",
       "      <th>OFFDETAIL</th>\n",
       "      <th>RACE</th>\n",
       "      <th>AGEADMIT</th>\n",
       "      <th>AGERELEASE</th>\n",
       "      <th>TIMESRVD</th>\n",
       "      <th>RELTYPE</th>\n",
       "      <th>STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2008</td>\n",
       "      <td>2009</td>\n",
       "      <td>2010</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2007</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287979</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2012</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404424</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488157</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491650</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>2014</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743263</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>2001</td>\n",
       "      <td>2021</td>\n",
       "      <td>2002</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086862</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2004</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2942323</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011</td>\n",
       "      <td>2007</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075560</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>2014</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        recidivism SEX ADMTYPE OFFGENERAL  ADMITYR  RELEASEYR  \\\n",
       "6                1   2       3          3     2008       2009   \n",
       "23               1   1       1          3     2007       2008   \n",
       "287979           0   1       1          2     2012       2013   \n",
       "404424           0   1       1          1     2012       2014   \n",
       "488157           0   1       2          1     2012       2013   \n",
       "491650           0   1       1          1     2012       2014   \n",
       "743263           0   1       2          2     2000       2001   \n",
       "2086862          0   2       2          1     2009       2009   \n",
       "2942323          0   2       2          2     2010       2011   \n",
       "3075560          0   1       1          1     2013       2014   \n",
       "\n",
       "         MAND_PRISREL_YEAR  PROJ_PRISREL_YEAR  PARELIG_YEAR SENTLGTH  \\\n",
       "6                     2010               2009          2009        2   \n",
       "23                    2008               2008          2007        1   \n",
       "287979                2013               2013          2013        3   \n",
       "404424                2014               2014          2014        3   \n",
       "488157                2013               2013          2011        4   \n",
       "491650                2013               2013          2013        3   \n",
       "743263                2021               2002          2020        2   \n",
       "2086862               2009               2004          2005        2   \n",
       "2942323               2011               2007          2015        2   \n",
       "3075560               2015               2015          2014        2   \n",
       "\n",
       "        OFFDETAIL RACE AGEADMIT AGERELEASE TIMESRVD RELTYPE STATE  \n",
       "6              12    1        2          2        0       1    18  \n",
       "23             12    2        4          4        1       2    44  \n",
       "287979         10    1        5          5        1       1     4  \n",
       "404424          1    1        4          4        1       1     4  \n",
       "488157          3    1        5          5        0       1     4  \n",
       "491650          3    1        3          3        1       1     4  \n",
       "743263          7    3        2          2        1       1     6  \n",
       "2086862         5    2        4          4        0       2     6  \n",
       "2942323        11    1        3          3        0       1     6  \n",
       "3075560         6    3        2          2        0       1     8  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_rows2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking of class imbalance in dataset to see if under/oversampling of dataset is required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to check for class imbalance in data set\n",
    "def print_data_perc(data_frame, col):\n",
    "    \"\"\"Function used to print class distribution\"\"\"\n",
    "    try:\n",
    "        # Stores value counts\n",
    "        col_vals = data_frame[col].value_counts()\n",
    "        # Resets index to make index a column in data frame\n",
    "        col_vals = col_vals.reset_index()\n",
    "        # If the number of unique instances in column exceeds 20 print warning\n",
    "        if len(col_vals['index']) > 20:\n",
    "            print('Warning: values in column are more than 20 \\nPlease try a column with lower value counts!')\n",
    "        # Else it calculates/prints percentage for each unique value in column\n",
    "        else:\n",
    "            # Create a function to output the percentage\n",
    "            f = lambda x, y: 100 * (x / sum(y))\n",
    "            for i in range(0, len(col_vals['index'])):\n",
    "                print('{0} accounts for {1:.2f}% of the {2} column'\\\n",
    "                      .format(col_vals['index'][i],\n",
    "                              f(col_vals[col].iloc[i],\n",
    "                                col_vals[col]),\n",
    "                              col))\n",
    "    # try-except block goes here if it can't find the column in data frame\n",
    "    except KeyError as e:\n",
    "        print('{0}: Not found'.format(e))\n",
    "        print('Please choose the right column name!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 accounts for 54.45% of the recidivism column\n",
      "1 accounts for 45.55% of the recidivism column\n"
     ]
    }
   ],
   "source": [
    "print_data_perc(complete_rows, 'recidivism') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 accounts for 54.45% of the recidivism column\n",
      "1 accounts for 45.55% of the recidivism column\n"
     ]
    }
   ],
   "source": [
    "print_data_perc(complete_rows2, 'recidivism') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-test split for Neural Network, Random Forest and Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X1,y1 are the datasets for neural network. X2,y2 are datasets for Random Forest and Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = complete_rows.iloc[:, 1:17]\n",
    "y1 = complete_rows.iloc[:, 0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = complete_rows2.iloc[:, 1:17]\n",
    "y2 = complete_rows2.iloc[:, 0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train1 (462720, 16) (462720, 1)\n",
      "Test1 (198309, 16) (198309, 1)\n",
      "Train2 (462720, 16) (462720, 1)\n",
      "Test2 (198309, 16) (198309, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Train1', X_train.shape, y_train.shape)\n",
    "print('Test1', X_test.shape, y_test.shape)\n",
    "print('Train2', X_train2.shape, y_train2.shape)\n",
    "print('Test2', X_test2.shape, y_test2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid and tanh should not be used as activation function for the hidden layer. This is because of the vanishing gradient problem, i.e., if your input is on a higher side (where sigmoid goes flat) then the gradient will be near zero. This will cause very slow or no learning during backpropagation as weights will be updated with really small values.\n",
    "\n",
    "The best function for hidden layers is thus ReLu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "# Import `Sequential` from `keras.models`\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Import `Dense` from `keras.layers`\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initialize the constructor\n",
    "model = Sequential()\n",
    "\n",
    "# Add an input layer of one-dimensional array with 16 elements for input.(Thus no need to flattenlayer) It would produce 17 outputs in return\n",
    "model.add(Dense(15, activation='relu', input_shape=(16,)))\n",
    "\n",
    "#Adding another hidden layer\n",
    "model.add(Dense(15, activation='relu'))\n",
    "\n",
    "# Add an output layer \n",
    "model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 15)                255       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 511\n",
      "Trainable params: 511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 1.75330341e-01,  4.30327654e-01,  2.69641519e-01,\n",
       "          4.25615251e-01,  2.12805212e-01,  3.89625430e-01,\n",
       "          3.83749127e-01, -1.82240218e-01, -1.81704849e-01,\n",
       "          1.63797975e-01, -2.67169774e-01,  3.60819936e-01,\n",
       "          3.38549137e-01, -2.73868144e-02,  2.50083387e-01],\n",
       "        [-4.13046986e-01,  2.70144701e-01, -3.83857071e-01,\n",
       "          1.31087661e-01, -4.02800351e-01, -2.53780454e-01,\n",
       "          3.69557798e-01,  1.16501510e-01, -1.50903523e-01,\n",
       "          1.69975162e-01,  1.52167022e-01,  1.51899576e-01,\n",
       "          1.25841558e-01, -2.03805104e-01,  3.49832833e-01],\n",
       "        [ 4.01247263e-01,  2.29769409e-01, -3.35857272e-03,\n",
       "         -6.00429177e-02, -3.80775422e-01,  2.90501893e-01,\n",
       "         -3.58591974e-01,  2.62086093e-02,  1.74820065e-01,\n",
       "         -1.62092477e-01, -3.58854532e-01, -9.21186507e-02,\n",
       "          1.57248139e-01, -2.27570593e-01,  3.64726603e-01],\n",
       "        [ 4.04798508e-01, -9.22504067e-02,  2.48901248e-02,\n",
       "          3.08461607e-01,  2.87582576e-01, -1.25157595e-01,\n",
       "          3.27250183e-01,  6.29137754e-02,  4.11962330e-01,\n",
       "          3.05148423e-01,  3.05008531e-01, -3.77004385e-01,\n",
       "          2.02283561e-01,  4.58107889e-02, -2.93505788e-02],\n",
       "        [ 2.56206155e-01,  1.96993828e-01, -3.45068812e-01,\n",
       "         -1.88488305e-01,  3.25004160e-01, -2.95033336e-01,\n",
       "         -2.31518984e-01,  1.44214451e-01, -2.85900772e-01,\n",
       "          2.13435590e-01,  2.11479485e-01, -3.62613142e-01,\n",
       "         -1.27002716e-01, -6.51867390e-02,  2.20793784e-02],\n",
       "        [ 1.34592235e-01,  3.01379859e-02,  1.43549263e-01,\n",
       "          1.55603886e-01,  3.99558127e-01, -3.16124767e-01,\n",
       "          2.05481648e-01,  1.41896784e-01, -6.16382062e-02,\n",
       "         -3.88662726e-01,  3.46193314e-01, -3.62622917e-01,\n",
       "         -9.70627666e-02,  1.93388641e-01, -4.33163345e-01],\n",
       "        [-3.12074006e-01,  1.67138219e-01,  1.37088358e-01,\n",
       "         -3.78254384e-01,  1.36515081e-01, -4.67594266e-02,\n",
       "          1.21589780e-01,  1.66577160e-01,  1.18223310e-01,\n",
       "          2.62043059e-01, -4.23747033e-01, -2.07879841e-02,\n",
       "          1.52364135e-01,  2.86068499e-01,  6.25440478e-02],\n",
       "        [-4.24177945e-02,  3.76951635e-01,  1.12576127e-01,\n",
       "          4.18832898e-02, -1.65724099e-01, -3.09897006e-01,\n",
       "          6.91668987e-02,  5.38744330e-02,  3.13561380e-01,\n",
       "          2.45667934e-01, -3.67334783e-01, -2.52384663e-01,\n",
       "         -4.22822207e-01, -1.33079022e-01,  1.90879405e-01],\n",
       "        [ 3.45817089e-01,  2.12688386e-01,  4.50143516e-02,\n",
       "         -2.96214104e-01, -1.78974450e-01, -3.01715493e-01,\n",
       "          7.08287954e-02, -1.25958651e-01, -3.62175435e-01,\n",
       "          5.84661961e-04,  3.75307143e-01,  1.74004436e-02,\n",
       "         -3.89479935e-01, -3.07515085e-01,  2.87659466e-01],\n",
       "        [ 2.76417673e-01, -3.73574287e-01, -3.12344968e-01,\n",
       "          1.46002114e-01, -1.59766436e-01,  2.06957996e-01,\n",
       "          3.00488770e-01,  2.24573553e-01,  2.43799508e-01,\n",
       "         -3.79729241e-01, -1.61028564e-01, -4.84485626e-02,\n",
       "          3.54209781e-01,  7.09710121e-02,  1.77017212e-01],\n",
       "        [-1.70240879e-01,  1.72673464e-02, -2.38556579e-01,\n",
       "          1.02779508e-01,  2.73709297e-01, -9.82890427e-02,\n",
       "          1.54115975e-01,  3.55144978e-01,  4.05623794e-01,\n",
       "         -1.05195940e-01,  3.83357823e-01,  8.47992897e-02,\n",
       "          3.43444288e-01, -3.60990167e-02, -3.81848007e-01],\n",
       "        [ 4.15964901e-01, -1.69661671e-01, -2.31862918e-01,\n",
       "          2.72827566e-01, -2.11988956e-01, -2.68703908e-01,\n",
       "         -1.44901395e-01,  3.53377163e-02, -1.31317377e-02,\n",
       "          1.28718197e-01, -2.01574191e-01,  4.02766585e-01,\n",
       "          4.09893990e-02, -2.22134247e-01, -2.67577589e-01],\n",
       "        [ 3.39316726e-02,  2.55230010e-01,  4.18397963e-01,\n",
       "          2.24977732e-04,  2.51294017e-01,  4.23979759e-01,\n",
       "         -1.25793666e-01, -2.69349396e-01,  3.88976455e-01,\n",
       "          2.94494510e-01,  2.50196338e-01,  2.97253132e-01,\n",
       "         -3.96034837e-01, -2.19292879e-01,  1.84353232e-01],\n",
       "        [-7.97307193e-02,  2.51753330e-02, -1.19882226e-02,\n",
       "         -4.84869480e-02, -6.00180626e-02,  1.98818624e-01,\n",
       "          2.40169168e-01, -1.12846434e-01,  2.82828093e-01,\n",
       "         -8.42350721e-03,  9.25241709e-02, -1.51275367e-01,\n",
       "          2.54837453e-01, -4.08592284e-01,  3.80021751e-01],\n",
       "        [ 4.29251969e-01,  2.48395205e-01,  1.14928901e-01,\n",
       "          1.45854712e-01, -3.73522341e-02,  2.37147570e-01,\n",
       "          2.84792066e-01, -2.16627613e-01,  1.27479851e-01,\n",
       "         -4.26582217e-01, -1.34035200e-01, -3.25637162e-01,\n",
       "         -3.54535758e-01,  3.12613249e-01,  8.90025496e-02],\n",
       "        [ 3.80974889e-01, -3.75460416e-01, -1.08805209e-01,\n",
       "         -2.44513407e-01,  9.52923298e-02,  6.60911202e-02,\n",
       "         -6.18818700e-02,  1.45596802e-01, -3.99983227e-01,\n",
       "          3.59604299e-01, -1.12090379e-01,  2.93094456e-01,\n",
       "          3.15933764e-01, -6.21450245e-02,  8.59100819e-02]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([[-0.3980693 , -0.3129976 ,  0.00519559, -0.02566046, -0.44048902,\n",
       "          0.06620991, -0.07028985,  0.10699511,  0.11769813, -0.35508382,\n",
       "          0.3062238 , -0.02707067, -0.12191424, -0.0375452 , -0.08523643],\n",
       "        [ 0.4470672 ,  0.4378037 , -0.4066389 ,  0.15813369,  0.20960695,\n",
       "         -0.24372002, -0.20044763,  0.2611568 , -0.39606315,  0.24218273,\n",
       "          0.05982715, -0.20665497,  0.19339031, -0.3662241 ,  0.30101496],\n",
       "        [-0.25812995,  0.01181853,  0.3245468 ,  0.05987608,  0.43689376,\n",
       "         -0.11366802,  0.12432373,  0.4147488 ,  0.22980827, -0.24773902,\n",
       "          0.11721146,  0.33977646,  0.38823068, -0.30756938, -0.22878756],\n",
       "        [ 0.09196728,  0.06384772, -0.15104446, -0.26543605,  0.32720792,\n",
       "          0.11407405,  0.39956808,  0.11353827, -0.1918002 , -0.3050863 ,\n",
       "         -0.17916739,  0.2460199 , -0.2848703 ,  0.27982986,  0.28697568],\n",
       "        [-0.2135497 , -0.3413449 ,  0.24804866,  0.04092807, -0.32326442,\n",
       "         -0.0831435 ,  0.05995983,  0.42203015, -0.28774852, -0.1957357 ,\n",
       "          0.0799706 ,  0.43412626, -0.18745965,  0.31516248, -0.14001921],\n",
       "        [ 0.18470043, -0.08334023,  0.30390793,  0.29347998, -0.03854671,\n",
       "         -0.34573704,  0.17586046,  0.09381306,  0.27626938, -0.264328  ,\n",
       "          0.19543767, -0.3355118 , -0.00960833,  0.36546952,  0.262765  ],\n",
       "        [ 0.28332597, -0.43522403, -0.17979637,  0.06208825,  0.39871693,\n",
       "          0.13766193, -0.17134705, -0.16864222, -0.43787023, -0.18669036,\n",
       "         -0.30496585, -0.37149763,  0.25173026, -0.12207353,  0.1652894 ],\n",
       "        [ 0.18663436,  0.0840528 , -0.3136016 , -0.06885642, -0.4075613 ,\n",
       "          0.07031995,  0.25780743, -0.10370201,  0.0777784 ,  0.19435084,\n",
       "          0.17945802, -0.30293328, -0.1129221 , -0.4069255 ,  0.2816478 ],\n",
       "        [ 0.38293964,  0.15296072,  0.09994841,  0.09671122,  0.06647259,\n",
       "          0.10357225,  0.0040082 , -0.2504095 ,  0.42200094,  0.3710001 ,\n",
       "         -0.1242089 , -0.37752688,  0.21184349, -0.01975626,  0.0490061 ],\n",
       "        [-0.22355476,  0.12900025,  0.22315234, -0.04017338,  0.2994542 ,\n",
       "          0.03215334, -0.37925315,  0.24297869, -0.17459941,  0.38355297,\n",
       "         -0.37063983, -0.33444098,  0.02538025, -0.13487214,  0.28264248],\n",
       "        [ 0.07766461, -0.34626484, -0.37934196,  0.42502022, -0.15742749,\n",
       "          0.2944557 , -0.17152289, -0.31543857, -0.09653717, -0.20901796,\n",
       "         -0.41146085,  0.27534246,  0.22701609,  0.16700757, -0.19686124],\n",
       "        [-0.22384414,  0.22184771,  0.42808694, -0.11989969, -0.05806628,\n",
       "         -0.06369475, -0.29600048,  0.24109358,  0.43658704,  0.0666669 ,\n",
       "          0.22673237,  0.41539145, -0.19260073,  0.33279032, -0.20214956],\n",
       "        [ 0.08172894, -0.38397413, -0.2796307 ,  0.4267934 , -0.20253436,\n",
       "         -0.15799347, -0.23927402, -0.19677314,  0.01741862, -0.02552834,\n",
       "         -0.05192176,  0.2476064 , -0.41083774, -0.17822504, -0.41758373],\n",
       "        [ 0.28007954, -0.23253337,  0.16646487, -0.40611216, -0.18389809,\n",
       "         -0.10984525,  0.36554772,  0.26307285,  0.06431752,  0.16923422,\n",
       "         -0.44598207, -0.04191104, -0.1571266 ,  0.32955098, -0.38752428],\n",
       "        [-0.22285424,  0.24785268,  0.2702806 ,  0.21616358,  0.26792932,\n",
       "         -0.4220577 ,  0.09736073,  0.12865222,  0.14262658, -0.28140843,\n",
       "          0.2292974 , -0.2002057 , -0.23436132, -0.40402466, -0.42355937]],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([[ 0.51299804],\n",
       "        [ 0.12098998],\n",
       "        [ 0.18749398],\n",
       "        [ 0.15412682],\n",
       "        [-0.4591275 ],\n",
       "        [-0.57928   ],\n",
       "        [-0.5126329 ],\n",
       "        [ 0.54747814],\n",
       "        [-0.40695828],\n",
       "        [ 0.02746338],\n",
       "        [-0.11397684],\n",
       "        [ 0.49773556],\n",
       "        [ 0.20059437],\n",
       "        [ 0.33040297],\n",
       "        [ 0.5558811 ]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model output shape\n",
    "model.output_shape\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "# Model config\n",
    "model.get_config()\n",
    "\n",
    "# List all weight tensors \n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used binary_crossentropy because our target variable y is a binary variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# An epoch is a single pass through the entire training set, followed by testing of the verification set. \n",
    "#The batch size that you specify in the code above defines the number of samples that going to be propagated through the network. \n",
    "#Also, by doing this, you optimize the efficiency because you make sure that you don’t load too many input patterns into memory at the same time.\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "                   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determinig Batch size and Epoch for the neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.767546 using {'batch_size': 20, 'epochs': 100}\n",
      "0.755241 (0.005048) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.763840 (0.005977) with: {'batch_size': 10, 'epochs': 50}\n",
      "0.766098 (0.002102) with: {'batch_size': 10, 'epochs': 100}\n",
      "0.748014 (0.006264) with: {'batch_size': 20, 'epochs': 10}\n",
      "0.757121 (0.009635) with: {'batch_size': 20, 'epochs': 50}\n",
      "0.767546 (0.001535) with: {'batch_size': 20, 'epochs': 100}\n",
      "0.734271 (0.017954) with: {'batch_size': 40, 'epochs': 10}\n",
      "0.762569 (0.000755) with: {'batch_size': 40, 'epochs': 50}\n",
      "0.761821 (0.006023) with: {'batch_size': 40, 'epochs': 100}\n",
      "0.741837 (0.001669) with: {'batch_size': 60, 'epochs': 10}\n",
      "0.765219 (0.003053) with: {'batch_size': 60, 'epochs': 50}\n",
      "0.765701 (0.000730) with: {'batch_size': 60, 'epochs': 100}\n",
      "0.737649 (0.006900) with: {'batch_size': 80, 'epochs': 10}\n",
      "0.763109 (0.004159) with: {'batch_size': 80, 'epochs': 50}\n",
      "0.764315 (0.002395) with: {'batch_size': 80, 'epochs': 100}\n",
      "0.734704 (0.009567) with: {'batch_size': 100, 'epochs': 10}\n",
      "0.757277 (0.002629) with: {'batch_size': 100, 'epochs': 50}\n",
      "0.762939 (0.004517) with: {'batch_size': 100, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(15, activation='relu', input_shape=(16,)))\n",
    "    model.add(Dense(15, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "# define the grid search parameters\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run: tensorboard --logdir ./Graph on anaconda prompt.\n",
    "\n",
    "http://localhost:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23136/23136 [==============================] - 21s 868us/step - loss: 0.6266 - accuracy: 0.6352\n",
      "Epoch 2/100\n",
      "23136/23136 [==============================] - 19s 816us/step - loss: 0.5844 - accuracy: 0.6815\n",
      "Epoch 3/100\n",
      "23136/23136 [==============================] - 19s 833us/step - loss: 0.5442 - accuracy: 0.7164\n",
      "Epoch 4/100\n",
      "23136/23136 [==============================] - 19s 838us/step - loss: 0.5202 - accuracy: 0.7321\n",
      "Epoch 5/100\n",
      "23136/23136 [==============================] - 18s 783us/step - loss: 0.5115 - accuracy: 0.7382\n",
      "Epoch 6/100\n",
      "23136/23136 [==============================] - 20s 865us/step - loss: 0.5056 - accuracy: 0.7429\n",
      "Epoch 7/100\n",
      "23136/23136 [==============================] - 18s 794us/step - loss: 0.5010 - accuracy: 0.7458\n",
      "Epoch 8/100\n",
      "23136/23136 [==============================] - 19s 825us/step - loss: 0.4961 - accuracy: 0.7475\n",
      "Epoch 9/100\n",
      "23136/23136 [==============================] - 20s 864us/step - loss: 0.4923 - accuracy: 0.7502\n",
      "Epoch 10/100\n",
      "23136/23136 [==============================] - 20s 848us/step - loss: 0.4910 - accuracy: 0.7505\n",
      "Epoch 11/100\n",
      "23136/23136 [==============================] - 19s 839us/step - loss: 0.4893 - accuracy: 0.7518\n",
      "Epoch 12/100\n",
      "23136/23136 [==============================] - 20s 850us/step - loss: 0.4885 - accuracy: 0.7532\n",
      "Epoch 13/100\n",
      "23136/23136 [==============================] - 21s 889us/step - loss: 0.4866 - accuracy: 0.7542\n",
      "Epoch 14/100\n",
      "23136/23136 [==============================] - 19s 823us/step - loss: 0.4842 - accuracy: 0.7545\n",
      "Epoch 15/100\n",
      "23136/23136 [==============================] - 19s 820us/step - loss: 0.4835 - accuracy: 0.7556\n",
      "Epoch 16/100\n",
      "23136/23136 [==============================] - 19s 831us/step - loss: 0.4793 - accuracy: 0.7580\n",
      "Epoch 17/100\n",
      "23136/23136 [==============================] - 20s 851us/step - loss: 0.4822 - accuracy: 0.7578\n",
      "Epoch 18/100\n",
      "23136/23136 [==============================] - 20s 859us/step - loss: 0.4789 - accuracy: 0.7601\n",
      "Epoch 19/100\n",
      "23136/23136 [==============================] - 19s 823us/step - loss: 0.4797 - accuracy: 0.7597\n",
      "Epoch 20/100\n",
      "23136/23136 [==============================] - 20s 879us/step - loss: 0.4773 - accuracy: 0.7593\n",
      "Epoch 21/100\n",
      "23136/23136 [==============================] - 21s 920us/step - loss: 0.4769 - accuracy: 0.7593\n",
      "Epoch 22/100\n",
      "23136/23136 [==============================] - 19s 831us/step - loss: 0.4756 - accuracy: 0.7614\n",
      "Epoch 23/100\n",
      "23136/23136 [==============================] - 19s 841us/step - loss: 0.4745 - accuracy: 0.7602\n",
      "Epoch 24/100\n",
      "23136/23136 [==============================] - 20s 866us/step - loss: 0.4746 - accuracy: 0.7627\n",
      "Epoch 25/100\n",
      "23136/23136 [==============================] - 19s 824us/step - loss: 0.4733 - accuracy: 0.7623\n",
      "Epoch 26/100\n",
      "23136/23136 [==============================] - 20s 863us/step - loss: 0.4718 - accuracy: 0.7635\n",
      "Epoch 27/100\n",
      "23136/23136 [==============================] - 20s 881us/step - loss: 0.4740 - accuracy: 0.7636\n",
      "Epoch 28/100\n",
      "23136/23136 [==============================] - 20s 861us/step - loss: 0.4749 - accuracy: 0.7650\n",
      "Epoch 29/100\n",
      "23136/23136 [==============================] - 20s 873us/step - loss: 0.4718 - accuracy: 0.7632\n",
      "Epoch 30/100\n",
      "23136/23136 [==============================] - 19s 804us/step - loss: 0.4714 - accuracy: 0.7643\n",
      "Epoch 31/100\n",
      "23136/23136 [==============================] - 20s 844us/step - loss: 0.4713 - accuracy: 0.7640\n",
      "Epoch 32/100\n",
      "23136/23136 [==============================] - 20s 876us/step - loss: 0.4718 - accuracy: 0.7635\n",
      "Epoch 33/100\n",
      "23136/23136 [==============================] - 20s 883us/step - loss: 0.4691 - accuracy: 0.7654\n",
      "Epoch 34/100\n",
      "23136/23136 [==============================] - 19s 829us/step - loss: 0.4690 - accuracy: 0.7655\n",
      "Epoch 35/100\n",
      "23136/23136 [==============================] - 19s 829us/step - loss: 0.4702 - accuracy: 0.7644\n",
      "Epoch 36/100\n",
      "23136/23136 [==============================] - 19s 821us/step - loss: 0.4705 - accuracy: 0.7652\n",
      "Epoch 37/100\n",
      "23136/23136 [==============================] - 21s 895us/step - loss: 0.4688 - accuracy: 0.7653\n",
      "Epoch 38/100\n",
      "23136/23136 [==============================] - 20s 864us/step - loss: 0.4802 - accuracy: 0.7640\n",
      "Epoch 39/100\n",
      "23136/23136 [==============================] - 20s 879us/step - loss: 0.4691 - accuracy: 0.7644\n",
      "Epoch 40/100\n",
      "23136/23136 [==============================] - 38s 2ms/step - loss: 0.4709 - accuracy: 0.7640\n",
      "Epoch 41/100\n",
      "23136/23136 [==============================] - 29s 1ms/step - loss: 0.4800 - accuracy: 0.7634\n",
      "Epoch 42/100\n",
      "23136/23136 [==============================] - 24s 1ms/step - loss: 0.4716 - accuracy: 0.7642\n",
      "Epoch 43/100\n",
      "23136/23136 [==============================] - 23s 975us/step - loss: 0.4683 - accuracy: 0.7652\n",
      "Epoch 44/100\n",
      "23136/23136 [==============================] - 22s 966us/step - loss: 0.4680 - accuracy: 0.7650\n",
      "Epoch 45/100\n",
      "23136/23136 [==============================] - 21s 924us/step - loss: 0.4703 - accuracy: 0.7646\n",
      "Epoch 46/100\n",
      "23136/23136 [==============================] - 22s 970us/step - loss: 0.4687 - accuracy: 0.7660\n",
      "Epoch 47/100\n",
      "23136/23136 [==============================] - 24s 1ms/step - loss: 0.4690 - accuracy: 0.7658\n",
      "Epoch 48/100\n",
      "23136/23136 [==============================] - 21s 889us/step - loss: 0.4684 - accuracy: 0.7653\n",
      "Epoch 49/100\n",
      "23136/23136 [==============================] - 25s 1ms/step - loss: 0.4675 - accuracy: 0.7658\n",
      "Epoch 50/100\n",
      "23136/23136 [==============================] - 19s 834us/step - loss: 0.4670 - accuracy: 0.7655\n",
      "Epoch 51/100\n",
      "23136/23136 [==============================] - 22s 939us/step - loss: 0.4674 - accuracy: 0.7656\n",
      "Epoch 52/100\n",
      "23136/23136 [==============================] - 22s 954us/step - loss: 0.4666 - accuracy: 0.7672\n",
      "Epoch 53/100\n",
      "23136/23136 [==============================] - 22s 959us/step - loss: 0.4680 - accuracy: 0.7652\n",
      "Epoch 54/100\n",
      "23136/23136 [==============================] - 23s 974us/step - loss: 0.4670 - accuracy: 0.7659\n",
      "Epoch 55/100\n",
      "23136/23136 [==============================] - 22s 970us/step - loss: 0.4663 - accuracy: 0.7663\n",
      "Epoch 56/100\n",
      "23136/23136 [==============================] - 23s 1000us/step - loss: 0.4674 - accuracy: 0.7657\n",
      "Epoch 57/100\n",
      "23136/23136 [==============================] - 23s 986us/step - loss: 0.4763 - accuracy: 0.7662\n",
      "Epoch 58/100\n",
      "23136/23136 [==============================] - 23s 996us/step - loss: 0.4688 - accuracy: 0.7662\n",
      "Epoch 59/100\n",
      "23136/23136 [==============================] - 22s 971us/step - loss: 0.4655 - accuracy: 0.7667\n",
      "Epoch 60/100\n",
      "23136/23136 [==============================] - 24s 1ms/step - loss: 0.4703 - accuracy: 0.7654\n",
      "Epoch 61/100\n",
      "23136/23136 [==============================] - 25s 1ms/step - loss: 0.4672 - accuracy: 0.7663\n",
      "Epoch 62/100\n",
      "23136/23136 [==============================] - 28s 1ms/step - loss: 0.4676 - accuracy: 0.7665\n",
      "Epoch 63/100\n",
      "23136/23136 [==============================] - 23s 981us/step - loss: 0.4662 - accuracy: 0.7665\n",
      "Epoch 64/100\n",
      "23136/23136 [==============================] - 22s 967us/step - loss: 0.4670 - accuracy: 0.7662\n",
      "Epoch 65/100\n",
      "23136/23136 [==============================] - 25s 1ms/step - loss: 0.4661 - accuracy: 0.7674\n",
      "Epoch 66/100\n",
      "23136/23136 [==============================] - 24s 1ms/step - loss: 0.4659 - accuracy: 0.7663\n",
      "Epoch 67/100\n",
      "23136/23136 [==============================] - 22s 962us/step - loss: 0.4675 - accuracy: 0.7668\n",
      "Epoch 68/100\n",
      "23136/23136 [==============================] - 24s 1ms/step - loss: 0.4673 - accuracy: 0.7672\n",
      "Epoch 69/100\n",
      "23136/23136 [==============================] - 23s 983us/step - loss: 0.4696 - accuracy: 0.7665\n",
      "Epoch 70/100\n",
      "23136/23136 [==============================] - 23s 973us/step - loss: 0.4684 - accuracy: 0.7665\n",
      "Epoch 71/100\n",
      "23136/23136 [==============================] - 25s 1ms/step - loss: 0.4719 - accuracy: 0.7657\n",
      "Epoch 72/100\n",
      "23136/23136 [==============================] - 27s 1ms/step - loss: 0.4683 - accuracy: 0.7678\n",
      "Epoch 73/100\n",
      "23136/23136 [==============================] - 28s 1ms/step - loss: 0.4666 - accuracy: 0.7670\n",
      "Epoch 74/100\n",
      "23136/23136 [==============================] - 28s 1ms/step - loss: 0.4673 - accuracy: 0.7664\n",
      "Epoch 75/100\n",
      "23136/23136 [==============================] - 24s 1ms/step - loss: 0.4718 - accuracy: 0.7674\n",
      "Epoch 76/100\n",
      "23136/23136 [==============================] - 24s 1ms/step - loss: 0.4656 - accuracy: 0.7667\n",
      "Epoch 77/100\n",
      "23136/23136 [==============================] - 23s 997us/step - loss: 0.4650 - accuracy: 0.7673\n",
      "Epoch 78/100\n",
      "23136/23136 [==============================] - 21s 915us/step - loss: 0.4663 - accuracy: 0.7673\n",
      "Epoch 79/100\n",
      "23136/23136 [==============================] - 23s 995us/step - loss: 0.4681 - accuracy: 0.7670\n",
      "Epoch 80/100\n",
      "23136/23136 [==============================] - 22s 960us/step - loss: 0.4656 - accuracy: 0.7679\n",
      "Epoch 81/100\n",
      "23136/23136 [==============================] - 21s 920us/step - loss: 0.4664 - accuracy: 0.7680\n",
      "Epoch 82/100\n",
      "23136/23136 [==============================] - 21s 895us/step - loss: 0.4658 - accuracy: 0.7673\n",
      "Epoch 83/100\n",
      "23136/23136 [==============================] - 22s 931us/step - loss: 0.4656 - accuracy: 0.7680\n",
      "Epoch 84/100\n",
      "23136/23136 [==============================] - 24s 1ms/step - loss: 0.4681 - accuracy: 0.7674\n",
      "Epoch 85/100\n",
      "23136/23136 [==============================] - 21s 913us/step - loss: 0.4665 - accuracy: 0.7673\n",
      "Epoch 86/100\n",
      "23136/23136 [==============================] - 22s 942us/step - loss: 0.4664 - accuracy: 0.7663\n",
      "Epoch 87/100\n",
      "23136/23136 [==============================] - 23s 993us/step - loss: 0.4650 - accuracy: 0.7679\n",
      "Epoch 88/100\n",
      "23136/23136 [==============================] - 26s 1ms/step - loss: 0.4652 - accuracy: 0.7666\n",
      "Epoch 89/100\n",
      "23136/23136 [==============================] - 22s 956us/step - loss: 0.4655 - accuracy: 0.7669\n",
      "Epoch 90/100\n",
      "23136/23136 [==============================] - 20s 861us/step - loss: 0.4656 - accuracy: 0.7679\n",
      "Epoch 91/100\n",
      "23136/23136 [==============================] - 22s 949us/step - loss: 0.4653 - accuracy: 0.7676\n",
      "Epoch 92/100\n",
      "23136/23136 [==============================] - 21s 918us/step - loss: 0.4646 - accuracy: 0.7676\n",
      "Epoch 93/100\n",
      "23136/23136 [==============================] - 21s 891us/step - loss: 0.4636 - accuracy: 0.7684\n",
      "Epoch 94/100\n",
      "23136/23136 [==============================] - 23s 999us/step - loss: 0.4689 - accuracy: 0.7664\n",
      "Epoch 95/100\n",
      "23136/23136 [==============================] - 25s 1ms/step - loss: 0.4665 - accuracy: 0.7676\n",
      "Epoch 96/100\n",
      "23136/23136 [==============================] - 25s 1ms/step - loss: 0.4657 - accuracy: 0.7677\n",
      "Epoch 97/100\n",
      "23136/23136 [==============================] - 24s 1ms/step - loss: 0.4671 - accuracy: 0.7683\n",
      "Epoch 98/100\n",
      "23136/23136 [==============================] - 23s 983us/step - loss: 0.4640 - accuracy: 0.7686\n",
      "Epoch 99/100\n",
      "23136/23136 [==============================] - 21s 922us/step - loss: 0.4648 - accuracy: 0.7680\n",
      "Epoch 100/100\n",
      "23136/23136 [==============================] - 24s 1ms/step - loss: 0.4659 - accuracy: 0.7674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bba8b371f0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,epochs=100, batch_size=20, verbose=1, callbacks=[keras.callbacks.TensorBoard(log_dir='./Graph', write_graph=True, write_images=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ann_visualizer.visualize import ann_viz;\n",
    "\n",
    "ann_viz(model, filename= \"nn1.gv\", title=\"My first neural network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN model test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46064037],\n",
       "       [0.28865907],\n",
       "       [0.9879695 ],\n",
       "       ...,\n",
       "       [0.00207418],\n",
       "       [0.5242503 ],\n",
       "       [0.9348106 ]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6198/6198 [==============================] - 5s 705us/step - loss: 0.4657 - accuracy: 0.7670\n",
      "[0.4656701385974884, 0.7669697403907776]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test,verbose=1)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[93136, 14771],\n",
       "       [31441, 58961]], dtype=int64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, cohen_kappa_score, accuracy_score\n",
    "rounded = [round(x[0]) for x in y_pred]\n",
    "# Confusion matrix\n",
    "confusion_matrix(y_test, rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7669697290591955\n",
      "Precision:  0.7996663592470027\n",
      "Recall:  0.6522090219242938\n",
      "F1 score:  0.7184495595062571\n",
      "Cohen Kappa Score:  0.5231472627768783\n"
     ]
    }
   ],
   "source": [
    "# Accuracy \n",
    "print(\"Accuracy: \", accuracy_score(y_test, rounded))\n",
    "print(\"Precision: \", precision_score(y_test, rounded))\n",
    "print(\"Recall: \", recall_score(y_test, rounded))\n",
    "print(\"F1 score: \", f1_score(y_test, rounded))\n",
    "print(\"Cohen Kappa Score: \", cohen_kappa_score(y_test, rounded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Random Forest Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 500,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': True,\n",
      " 'random_state': None,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n",
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 2,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 500,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': True,\n",
      " 'random_state': None,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "#Create a Gaussian Classifier\n",
    "clf1 = RandomForestClassifier(n_estimators=500, oob_score=True)\n",
    "clf2 = RandomForestClassifier(n_estimators=500, oob_score=True, max_features = \"auto\", min_samples_leaf = 2)\n",
    "\n",
    "from pprint import pprint\n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "#max_features by default is auto and min_samples_leaf is 1.\n",
    "pprint(clf1.get_params())\n",
    "\n",
    "pprint(clf2.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-73-090b547ca29f>:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf1.fit(X_train2,y_train2)\n",
      "<ipython-input-73-090b547ca29f>:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf2.fit(X_train2,y_train2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(min_samples_leaf=2, n_estimators=500, oob_score=True)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(X_train2,y_train2)\n",
    "clf2.fit(X_train2,y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing Between clf1 and clf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7658603492529336\n",
      "Precision score:  0.7608257207260648\n",
      "Recall score:  0.7093869604654764\n"
     ]
    }
   ],
   "source": [
    "y_pred2=clf1.predict(X_test2)\n",
    "print(\"Accuracy:\", accuracy_score(y_test2, y_pred2))\n",
    "print(\"Precision score: \", precision_score(y_test2, y_pred2))\n",
    "print(\"Recall score: \", recall_score(y_test2, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7790972673958317\n",
      "Precision score:  0.7858273319510729\n",
      "Recall score:  0.7085241476958475\n"
     ]
    }
   ],
   "source": [
    "y_pred2=clf2.predict(X_test2)\n",
    "print(\"Accuracy:\", accuracy_score(y_test2, y_pred2))\n",
    "print(\"Precision score: \", precision_score(y_test2, y_pred2))\n",
    "print(\"Recall score: \", recall_score(y_test2, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLF1 score:  0.9406206777316736\n",
      "CLF2 score:  0.8872687586445367\n"
     ]
    }
   ],
   "source": [
    "print(\"CLF1 score: \", clf1.score(X_train2, y_train2))\n",
    "print(\"CLF2 score: \", clf2.score(X_train2, y_train2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLF1 oobscore:  0.7667725622406639\n",
      "CLF2 oobscore:  0.7793806189488244\n"
     ]
    }
   ],
   "source": [
    "print(\"CLF1 oobscore: \", clf1.oob_score_)\n",
    "print(\"CLF2 oobscore: \", clf2.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, random forest model accuracy increased by 0.01 when i increased min_samples_leaf from 1 to 2. Thus, we will be using clf2 for our further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection for Random Forest Classifier Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 'feature_importances'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SEX', 0.011466754571740408)\n",
      "('ADMTYPE', 0.04886226474072332)\n",
      "('OFFGENERAL', 0.028840394379042962)\n",
      "('ADMITYR', 0.0867622636711505)\n",
      "('RELEASEYR', 0.06913643400336503)\n",
      "('MAND_PRISREL_YEAR', 0.07374964563261392)\n",
      "('PROJ_PRISREL_YEAR', 0.06541202920779508)\n",
      "('PARELIG_YEAR', 0.1484453928038904)\n",
      "('SENTLGTH', 0.040065177466930335)\n",
      "('OFFDETAIL', 0.05604473035183856)\n",
      "('RACE', 0.034781562904497146)\n",
      "('AGEADMIT', 0.03393877571716159)\n",
      "('AGERELEASE', 0.035632804529097464)\n",
      "('TIMESRVD', 0.08723491983309074)\n",
      "('RELTYPE', 0.01852666729774538)\n",
      "('STATE', 0.1611001828893171)\n"
     ]
    }
   ],
   "source": [
    "feat_labels = ['SEX','ADMTYPE','OFFGENERAL','ADMITYR','RELEASEYR','MAND_PRISREL_YEAR','PROJ_PRISREL_YEAR','PARELIG_YEAR','SENTLGTH','OFFDETAIL','RACE','AGEADMIT','AGERELEASE','TIMESRVD','RELTYPE','STATE']\n",
    "for feature in zip(feat_labels, clf2.feature_importances_):\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using sklearn SelectfromModel for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=RandomForestClassifier(min_samples_leaf=2,\n",
       "                                                 n_estimators=500,\n",
       "                                                 oob_score=True))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "# Create a selector object that will use the random forest classifier to identify\n",
    "# features that have an importance of more than 0.15\n",
    "sfm = SelectFromModel(clf2)\n",
    "\n",
    "# Train the selector\n",
    "sfm.fit(X_train2, y_train2.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADMITYR\n",
      "RELEASEYR\n",
      "MAND_PRISREL_YEAR\n",
      "PROJ_PRISREL_YEAR\n",
      "PARELIG_YEAR\n",
      "TIMESRVD\n",
      "STATE\n"
     ]
    }
   ],
   "source": [
    "# Print the names of the most important features\n",
    "for feature_list_index in sfm.get_support(indices=True):\n",
    "    print(feat_labels[feature_list_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data to create a new dataset containing only the most important features\n",
    "# Note: We have to apply the transform to both the training X and test X data.\n",
    "X_important_train = sfm.transform(X_train2)\n",
    "X_important_test = sfm.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-94-7d24d2ac47a1>:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf_important.fit(X_important_train, y_train2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=500, oob_score=True)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new random forest classifier for the most important features\n",
    "clf_important = RandomForestClassifier(n_estimators=500, oob_score=True)\n",
    "\n",
    "# Train the new classifier on the new dataset containing the most important features\n",
    "clf_important.fit(X_important_train, y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier Model Results (clf2 vs clf_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clf2 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7790972673958317\n",
      "Precision score:  0.7858273319510729\n",
      "Recall score:  0.7085241476958475\n"
     ]
    }
   ],
   "source": [
    "y_pred2=clf2.predict(X_test2)\n",
    "print(\"Accuracy:\", accuracy_score(y_test2, y_pred2))\n",
    "print(\"Precision score: \", precision_score(y_test2, y_pred2))\n",
    "print(\"Recall score: \", recall_score(y_test2, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[90450, 17457],\n",
       "       [26350, 64052]], dtype=int64)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test2, y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clf_importance results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7514585823134603\n",
      "Precision score:  0.7593943217665615\n",
      "Recall score:  0.6657153602796398\n"
     ]
    }
   ],
   "source": [
    "# Apply The Full Featured Classifier To The Test Data\n",
    "y_important_pred = clf_important.predict(X_important_test)\n",
    "\n",
    "# View The Accuracy Of Our Limited Feature (8 Features) Model\n",
    "print(\"Accuracy:\", accuracy_score(y_test2, y_important_pred))\n",
    "print(\"Precision score: \", precision_score(y_test2, y_important_pred))\n",
    "print(\"Recall score: \", recall_score(y_test2, y_important_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[88839, 19068],\n",
       "       [30220, 60182]], dtype=int64)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test2, y_important_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf2 score:  0.8872687586445367\n",
      "clf_important score:  0.7968577109266943\n"
     ]
    }
   ],
   "source": [
    "print(\"clf2 score: \", clf2.score(X_train2, y_train2))\n",
    "print(\"clf_important score: \", clf_important.score(X_important_train, y_train2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, accuracy for model after feature selection has slightly deproved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf2 score oobscore:  0.7793806189488244\n",
      "clf_important oobscore:  0.7528224412171508\n"
     ]
    }
   ],
   "source": [
    "print(\"clf2 score oobscore: \", clf2.oob_score_)\n",
    "print(\"clf_important oobscore: \", clf_important.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(clf.score(X_test2,y_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using features selected from Random Forrest on NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using features selected from random forest model above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = complete_rows[['ADMITYR','RELEASEYR','MAND_PRISREL_YEAR','PROJ_PRISREL_YEAR','PARELIG_YEAR','OFFDETAIL','TIMESRVD','STATE']]\n",
    "y3 = complete_rows.iloc[:, 0:1]\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y3, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the constructor\n",
    "model2 = Sequential()\n",
    "\n",
    "# Add an input layer of one-dimensional array with 8 elements for input. (Thus no need to flattenlayer) It would produce 32 outputs in return\n",
    "model2.add(Dense(7, activation='relu', input_shape=(8,)))\n",
    "\n",
    "# # model.add(Flatten)\n",
    "\n",
    "# # Add one hidden layer \n",
    "model2.add(Dense(7, activation='relu'))\n",
    "\n",
    "# model2.add(Dense(128, activation='relu'))\n",
    "\n",
    "# model2.add(Dense(256, activation='relu'))\n",
    "\n",
    "# Add an output layer \n",
    "model2.add(Dense(1, activation='sigmoid')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 7)                 63        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 8         \n",
      "=================================================================\n",
      "Total params: 127\n",
      "Trainable params: 127\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.59417015, -0.56197065,  0.5135302 ,  0.5004445 , -0.57554424,\n",
       "          0.14618826,  0.11896282],\n",
       "        [ 0.36223972, -0.21884194, -0.33412206,  0.03615427, -0.5979334 ,\n",
       "          0.44025797, -0.08478165],\n",
       "        [ 0.1000635 ,  0.50888544, -0.42866158,  0.45969218,  0.4693306 ,\n",
       "         -0.45110804, -0.36519805],\n",
       "        [ 0.2162885 ,  0.28395814, -0.04310507,  0.00943863,  0.04421228,\n",
       "          0.5464309 ,  0.4105789 ],\n",
       "        [-0.57340044, -0.5533947 , -0.5625785 ,  0.5753588 , -0.4622479 ,\n",
       "         -0.25455424, -0.24743217],\n",
       "        [ 0.3961913 , -0.48524082, -0.6199085 , -0.48874065, -0.15720206,\n",
       "         -0.5595815 ,  0.5830721 ],\n",
       "        [ 0.14959127, -0.28740126,  0.08272672, -0.5242937 , -0.23317868,\n",
       "          0.14668167, -0.04814547],\n",
       "        [ 0.3794238 , -0.49679703, -0.01604563, -0.4542657 ,  0.13077295,\n",
       "          0.04789847, -0.20233372]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[-0.23330656,  0.13977844,  0.5055355 ,  0.35891843, -0.62679875,\n",
       "          0.5810709 ,  0.5179179 ],\n",
       "        [-0.4482966 ,  0.17916983, -0.49761152,  0.14195842, -0.1917564 ,\n",
       "          0.0497039 , -0.01731414],\n",
       "        [ 0.15122217, -0.35824472,  0.01387084, -0.61302155, -0.17914999,\n",
       "          0.43629158, -0.43110642],\n",
       "        [ 0.28231537,  0.39696455, -0.15891868, -0.04770011,  0.44696665,\n",
       "          0.51774263, -0.11005753],\n",
       "        [-0.6477934 , -0.35069507, -0.17036963, -0.00806975,  0.5627222 ,\n",
       "         -0.26799023,  0.33274394],\n",
       "        [-0.436018  , -0.43850157,  0.01947308,  0.10660481,  0.08039188,\n",
       "          0.53495824, -0.14010447],\n",
       "        [ 0.03108442,  0.37015545,  0.47344434,  0.3550657 ,  0.43194366,\n",
       "         -0.2645616 ,  0.43683505]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[-0.00592256],\n",
       "        [ 0.66509134],\n",
       "        [ 0.06429017],\n",
       "        [ 0.5364391 ],\n",
       "        [-0.33680022],\n",
       "        [ 0.64596146],\n",
       "        [ 0.8060083 ]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model output shape\n",
    "model2.output_shape\n",
    "\n",
    "# Model summary\n",
    "model2.summary()\n",
    "\n",
    "# Model config\n",
    "model2.get_config()\n",
    "\n",
    "# List all weight tensors \n",
    "model2.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23136/23136 [==============================] - 89s 3ms/step - loss: 0.8616 - accuracy: 0.5970\n",
      "Epoch 2/100\n",
      "23136/23136 [==============================] - 73s 3ms/step - loss: 0.6219 - accuracy: 0.6390\n",
      "Epoch 3/100\n",
      "23136/23136 [==============================] - 71s 3ms/step - loss: 0.6170 - accuracy: 0.6466\n",
      "Epoch 4/100\n",
      "23136/23136 [==============================] - 74s 3ms/step - loss: 0.6070 - accuracy: 0.6568\n",
      "Epoch 5/100\n",
      "23136/23136 [==============================] - 73s 3ms/step - loss: 0.5982 - accuracy: 0.6626\n",
      "Epoch 6/100\n",
      "23136/23136 [==============================] - 72s 3ms/step - loss: 0.5863 - accuracy: 0.6711\n",
      "Epoch 7/100\n",
      "23136/23136 [==============================] - 28s 1ms/step - loss: 0.5595 - accuracy: 0.6981\n",
      "Epoch 8/100\n",
      "23136/23136 [==============================] - 17s 748us/step - loss: 0.5507 - accuracy: 0.7101\n",
      "Epoch 9/100\n",
      "23136/23136 [==============================] - 17s 742us/step - loss: 0.5452 - accuracy: 0.7110\n",
      "Epoch 10/100\n",
      "23136/23136 [==============================] - 17s 749us/step - loss: 0.5440 - accuracy: 0.7105\n",
      "Epoch 11/100\n",
      "23136/23136 [==============================] - 17s 749us/step - loss: 0.5455 - accuracy: 0.7076\n",
      "Epoch 12/100\n",
      "23136/23136 [==============================] - 17s 749us/step - loss: 0.5420 - accuracy: 0.7085\n",
      "Epoch 13/100\n",
      "23136/23136 [==============================] - 17s 754us/step - loss: 0.5408 - accuracy: 0.7069\n",
      "Epoch 14/100\n",
      "23136/23136 [==============================] - 17s 736us/step - loss: 0.5400 - accuracy: 0.7058\n",
      "Epoch 15/100\n",
      "23136/23136 [==============================] - 16s 677us/step - loss: 0.5381 - accuracy: 0.7107\n",
      "Epoch 16/100\n",
      "23136/23136 [==============================] - 16s 690us/step - loss: 0.5384 - accuracy: 0.7112\n",
      "Epoch 17/100\n",
      "23136/23136 [==============================] - 16s 672us/step - loss: 0.5370 - accuracy: 0.7129\n",
      "Epoch 18/100\n",
      "23136/23136 [==============================] - 16s 697us/step - loss: 0.5383 - accuracy: 0.7133\n",
      "Epoch 19/100\n",
      "23136/23136 [==============================] - 19s 824us/step - loss: 0.5369 - accuracy: 0.7127\n",
      "Epoch 20/100\n",
      "23136/23136 [==============================] - 18s 783us/step - loss: 0.5366 - accuracy: 0.7135\n",
      "Epoch 21/100\n",
      "23136/23136 [==============================] - 17s 728us/step - loss: 0.5369 - accuracy: 0.7128\n",
      "Epoch 22/100\n",
      "23136/23136 [==============================] - 17s 718us/step - loss: 0.5362 - accuracy: 0.7142\n",
      "Epoch 23/100\n",
      "23136/23136 [==============================] - 17s 717us/step - loss: 0.5344 - accuracy: 0.7158\n",
      "Epoch 24/100\n",
      "23136/23136 [==============================] - 17s 746us/step - loss: 0.5351 - accuracy: 0.7150\n",
      "Epoch 25/100\n",
      "23136/23136 [==============================] - 17s 756us/step - loss: 0.5335 - accuracy: 0.7163\n",
      "Epoch 26/100\n",
      "23136/23136 [==============================] - 17s 719us/step - loss: 0.5319 - accuracy: 0.7170\n",
      "Epoch 27/100\n",
      "23136/23136 [==============================] - 17s 730us/step - loss: 0.5326 - accuracy: 0.7166\n",
      "Epoch 28/100\n",
      "23136/23136 [==============================] - 17s 717us/step - loss: 0.5329 - accuracy: 0.7168\n",
      "Epoch 29/100\n",
      "23136/23136 [==============================] - 17s 741us/step - loss: 0.5317 - accuracy: 0.7167\n",
      "Epoch 30/100\n",
      "23136/23136 [==============================] - 17s 725us/step - loss: 0.5306 - accuracy: 0.7194\n",
      "Epoch 31/100\n",
      "23136/23136 [==============================] - 17s 729us/step - loss: 0.5316 - accuracy: 0.7178\n",
      "Epoch 32/100\n",
      "23136/23136 [==============================] - 17s 731us/step - loss: 0.5287 - accuracy: 0.7192\n",
      "Epoch 33/100\n",
      "23136/23136 [==============================] - 17s 728us/step - loss: 0.5280 - accuracy: 0.7204\n",
      "Epoch 34/100\n",
      "23136/23136 [==============================] - 18s 757us/step - loss: 0.5304 - accuracy: 0.7197\n",
      "Epoch 35/100\n",
      "23136/23136 [==============================] - 17s 726us/step - loss: 0.5285 - accuracy: 0.7209\n",
      "Epoch 36/100\n",
      "23136/23136 [==============================] - 17s 738us/step - loss: 0.5269 - accuracy: 0.7220\n",
      "Epoch 37/100\n",
      "23136/23136 [==============================] - 17s 721us/step - loss: 0.5275 - accuracy: 0.7219\n",
      "Epoch 38/100\n",
      "23136/23136 [==============================] - 17s 731us/step - loss: 0.5265 - accuracy: 0.7231\n",
      "Epoch 39/100\n",
      "23136/23136 [==============================] - 17s 754us/step - loss: 0.5240 - accuracy: 0.7247\n",
      "Epoch 40/100\n",
      "23136/23136 [==============================] - 17s 735us/step - loss: 0.5250 - accuracy: 0.7243\n",
      "Epoch 41/100\n",
      "23136/23136 [==============================] - 17s 754us/step - loss: 0.5247 - accuracy: 0.7246\n",
      "Epoch 42/100\n",
      "23136/23136 [==============================] - 17s 750us/step - loss: 0.5238 - accuracy: 0.7253\n",
      "Epoch 43/100\n",
      "23136/23136 [==============================] - 17s 735us/step - loss: 0.5230 - accuracy: 0.7268\n",
      "Epoch 44/100\n",
      "23136/23136 [==============================] - 18s 762us/step - loss: 0.5216 - accuracy: 0.7275\n",
      "Epoch 45/100\n",
      "23136/23136 [==============================] - 18s 759us/step - loss: 0.5219 - accuracy: 0.7252\n",
      "Epoch 46/100\n",
      "23136/23136 [==============================] - 17s 744us/step - loss: 0.5212 - accuracy: 0.7254\n",
      "Epoch 47/100\n",
      "23136/23136 [==============================] - 17s 725us/step - loss: 0.5205 - accuracy: 0.7252\n",
      "Epoch 48/100\n",
      "23136/23136 [==============================] - 17s 738us/step - loss: 0.5204 - accuracy: 0.7257\n",
      "Epoch 49/100\n",
      "23136/23136 [==============================] - 17s 731us/step - loss: 0.5210 - accuracy: 0.7265\n",
      "Epoch 50/100\n",
      "23136/23136 [==============================] - 17s 736us/step - loss: 0.5200 - accuracy: 0.7266\n",
      "Epoch 51/100\n",
      "23136/23136 [==============================] - 17s 736us/step - loss: 0.5200 - accuracy: 0.7272\n",
      "Epoch 52/100\n",
      "23136/23136 [==============================] - 17s 756us/step - loss: 0.5197 - accuracy: 0.7265\n",
      "Epoch 53/100\n",
      "23136/23136 [==============================] - 17s 734us/step - loss: 0.5194 - accuracy: 0.7255\n",
      "Epoch 54/100\n",
      "23136/23136 [==============================] - 17s 730us/step - loss: 0.5193 - accuracy: 0.7267\n",
      "Epoch 55/100\n",
      "23136/23136 [==============================] - 17s 735us/step - loss: 0.5189 - accuracy: 0.7274\n",
      "Epoch 56/100\n",
      "23136/23136 [==============================] - 17s 738us/step - loss: 0.5200 - accuracy: 0.7274\n",
      "Epoch 57/100\n",
      "23136/23136 [==============================] - 17s 735us/step - loss: 0.5183 - accuracy: 0.7290\n",
      "Epoch 58/100\n",
      "23136/23136 [==============================] - 17s 732us/step - loss: 0.5200 - accuracy: 0.7271\n",
      "Epoch 59/100\n",
      "23136/23136 [==============================] - 18s 758us/step - loss: 0.5196 - accuracy: 0.7280\n",
      "Epoch 60/100\n",
      "23136/23136 [==============================] - 20s 857us/step - loss: 0.5201 - accuracy: 0.7265\n",
      "Epoch 61/100\n",
      "23136/23136 [==============================] - 17s 729us/step - loss: 0.5188 - accuracy: 0.7291\n",
      "Epoch 62/100\n",
      "23136/23136 [==============================] - 17s 744us/step - loss: 0.5185 - accuracy: 0.7283\n",
      "Epoch 63/100\n",
      "23136/23136 [==============================] - 17s 738us/step - loss: 0.5193 - accuracy: 0.7279\n",
      "Epoch 64/100\n",
      "23136/23136 [==============================] - 17s 740us/step - loss: 0.5186 - accuracy: 0.7281\n",
      "Epoch 65/100\n",
      "23136/23136 [==============================] - 17s 731us/step - loss: 0.5185 - accuracy: 0.7288\n",
      "Epoch 66/100\n",
      "23136/23136 [==============================] - 17s 740us/step - loss: 0.5181 - accuracy: 0.7283\n",
      "Epoch 67/100\n",
      "23136/23136 [==============================] - 17s 737us/step - loss: 0.5186 - accuracy: 0.7277\n",
      "Epoch 68/100\n",
      "23136/23136 [==============================] - 17s 748us/step - loss: 0.5193 - accuracy: 0.7279\n",
      "Epoch 69/100\n",
      "23136/23136 [==============================] - 19s 802us/step - loss: 0.5184 - accuracy: 0.7282\n",
      "Epoch 70/100\n",
      "23136/23136 [==============================] - 20s 874us/step - loss: 0.5170 - accuracy: 0.7285\n",
      "Epoch 71/100\n",
      "23136/23136 [==============================] - 23s 985us/step - loss: 0.5194 - accuracy: 0.7284\n",
      "Epoch 72/100\n",
      "23136/23136 [==============================] - 21s 917us/step - loss: 0.5184 - accuracy: 0.7293s - loss: 0.5184 - accuracy: 0.\n",
      "Epoch 73/100\n",
      "23136/23136 [==============================] - 21s 922us/step - loss: 0.5169 - accuracy: 0.7297\n",
      "Epoch 74/100\n",
      "23136/23136 [==============================] - 17s 749us/step - loss: 0.5179 - accuracy: 0.7302\n",
      "Epoch 75/100\n",
      "23136/23136 [==============================] - 19s 843us/step - loss: 0.5173 - accuracy: 0.7301\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23136/23136 [==============================] - 21s 905us/step - loss: 0.5174 - accuracy: 0.7307\n",
      "Epoch 77/100\n",
      "23136/23136 [==============================] - 17s 728us/step - loss: 0.5170 - accuracy: 0.7293\n",
      "Epoch 78/100\n",
      "23136/23136 [==============================] - 17s 735us/step - loss: 0.5180 - accuracy: 0.7293\n",
      "Epoch 79/100\n",
      "23136/23136 [==============================] - 17s 745us/step - loss: 0.5169 - accuracy: 0.7283\n",
      "Epoch 80/100\n",
      "23136/23136 [==============================] - 17s 731us/step - loss: 0.5159 - accuracy: 0.7302\n",
      "Epoch 81/100\n",
      "23136/23136 [==============================] - 17s 724us/step - loss: 0.5174 - accuracy: 0.7296\n",
      "Epoch 82/100\n",
      "23136/23136 [==============================] - 17s 725us/step - loss: 0.5171 - accuracy: 0.7308\n",
      "Epoch 83/100\n",
      "23136/23136 [==============================] - 17s 728us/step - loss: 0.5185 - accuracy: 0.7284\n",
      "Epoch 84/100\n",
      "23136/23136 [==============================] - 17s 725us/step - loss: 0.5176 - accuracy: 0.7282\n",
      "Epoch 85/100\n",
      "23136/23136 [==============================] - 17s 737us/step - loss: 0.5172 - accuracy: 0.7291\n",
      "Epoch 86/100\n",
      "23136/23136 [==============================] - 17s 732us/step - loss: 0.5168 - accuracy: 0.7302\n",
      "Epoch 87/100\n",
      "23136/23136 [==============================] - 17s 732us/step - loss: 0.5182 - accuracy: 0.7279\n",
      "Epoch 88/100\n",
      "23136/23136 [==============================] - 17s 725us/step - loss: 0.5183 - accuracy: 0.7287\n",
      "Epoch 89/100\n",
      "23136/23136 [==============================] - 17s 722us/step - loss: 0.5168 - accuracy: 0.7294\n",
      "Epoch 90/100\n",
      "23136/23136 [==============================] - 17s 735us/step - loss: 0.5176 - accuracy: 0.7283\n",
      "Epoch 91/100\n",
      "23136/23136 [==============================] - 17s 735us/step - loss: 0.5176 - accuracy: 0.7292\n",
      "Epoch 92/100\n",
      "23136/23136 [==============================] - 17s 726us/step - loss: 0.5166 - accuracy: 0.7289\n",
      "Epoch 93/100\n",
      "23136/23136 [==============================] - 17s 745us/step - loss: 0.5166 - accuracy: 0.7295\n",
      "Epoch 94/100\n",
      "23136/23136 [==============================] - 17s 721us/step - loss: 0.5171 - accuracy: 0.7288\n",
      "Epoch 95/100\n",
      "23136/23136 [==============================] - 17s 728us/step - loss: 0.5164 - accuracy: 0.7295\n",
      "Epoch 96/100\n",
      "23136/23136 [==============================] - 17s 744us/step - loss: 0.5176 - accuracy: 0.7286\n",
      "Epoch 97/100\n",
      "23136/23136 [==============================] - 19s 826us/step - loss: 0.5167 - accuracy: 0.7287\n",
      "Epoch 98/100\n",
      "23136/23136 [==============================] - 20s 854us/step - loss: 0.5170 - accuracy: 0.7288\n",
      "Epoch 99/100\n",
      "23136/23136 [==============================] - 17s 720us/step - loss: 0.5171 - accuracy: 0.7293\n",
      "Epoch 100/100\n",
      "23136/23136 [==============================] - 17s 727us/step - loss: 0.5173 - accuracy: 0.7291\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bbb34a17f0>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train3, y_train3, epochs=100, batch_size=20, verbose=1,callbacks=[keras.callbacks.TensorBoard(log_dir='./Graph', write_graph=True, write_images=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ann_visualizer.visualize import ann_viz;\n",
    "\n",
    "ann_viz(model2, filename= \"nn2.gv\", title=\"Neural Network revised\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[85943, 21964],\n",
       "       [32735, 57667]], dtype=int64)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred3 = model2.predict(X_test3)\n",
    "y_pred3\n",
    "rounded2 = [round(x[0]) for x in y_pred3]\n",
    "# Confusion matrix\n",
    "confusion_matrix(y_test3, rounded2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7241728817148995\n",
      "Precision:  0.7241777699639588\n",
      "Recall:  0.6378951793101922\n",
      "F1 score:  0.6783036234142784\n",
      "Cohen Kappa Score:  0.4385880835729684\n"
     ]
    }
   ],
   "source": [
    "# Accuracy \n",
    "print(\"Accuracy: \", accuracy_score(y_test3, rounded2))\n",
    "print(\"Precision: \", precision_score(y_test3, rounded2))\n",
    "print(\"Recall: \", recall_score(y_test3, rounded2))\n",
    "print(\"F1 score: \", f1_score(y_test3, rounded2))\n",
    "print(\"Cohen Kappa Score: \", cohen_kappa_score(y_test3, rounded2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
